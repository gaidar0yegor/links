# handlers/statistics/stats.py
from aiogram import Router, F
from aiogram.types import CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton, Message, Document
from aiogram.fsm.context import FSMContext
from services.sheets_api import sheets_api

import pandas as pd
import io
from datetime import datetime, timedelta
from typing import Dict, List, Any

router = Router()

def get_stats_keyboard() -> InlineKeyboardMarkup:
    """ÐšÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ð° Ð´Ð»Ñ Ð¼Ð¾Ð´ÑƒÐ»Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸."""
    buttons = [
        [InlineKeyboardButton(text="ðŸ“¤ Upload CSV Report", callback_data="stats_upload_csv")],
        [InlineKeyboardButton(text="ðŸ“Š View Analytics", callback_data="stats_view_analytics")],
        [InlineKeyboardButton(text="ðŸ”„ Refresh Data", callback_data="stats_refresh")],
        [InlineKeyboardButton(text="â¬…ï¸ Main Menu", callback_data="back_to_main_menu")]
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)

def get_analytics_keyboard() -> InlineKeyboardMarkup:
    """ÐšÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ð° Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð° Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸."""
    buttons = [
        [InlineKeyboardButton(text="ðŸ“… Last 7 Days", callback_data="analytics_period:7")],
        [InlineKeyboardButton(text="ðŸ“… Last 30 Days", callback_data="analytics_period:30")],
        [InlineKeyboardButton(text="ðŸ“… Last 90 Days", callback_data="analytics_period:90")],
        [InlineKeyboardButton(text="ðŸŽ¯ By Tracking ID", callback_data="analytics_tracking")],
        [InlineKeyboardButton(text="â¬…ï¸ Back to Stats", callback_data="back_to_stats")]
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)

# REMOVED: Duplicate handler for MainMenuCallback.STATS
# This is now handled by handlers/main_menu.py to avoid conflicts

@router.callback_query(F.data == "stats_refresh")
async def refresh_stats(callback: CallbackQuery):
    """ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð¸ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÑ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ñ€Ð¾Ð´Ð°Ð¶."""
    print(f"ðŸ”„ Stats refresh requested")

    # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ sheet 'statistics' ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ)
    try:
        stats_data = sheets_api.get_sheet_data("statistics")
        print(f"ðŸ“Š Retrieved {len(stats_data) if stats_data else 0} stats rows")
    except Exception as e:
        print(f"âŒ Error getting stats: {e}")
        stats_data = []

    # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
    text = "**ðŸ“Š Revenue Analytics**\n\n"
    if len(stats_data) > 1:
        headers = stats_data[0]
        latest_data = stats_data[1] # Ð‘ÐµÑ€ÐµÐ¼, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÑ‚Ñ€Ð¾ÐºÑƒ (Ð¾Ð±Ñ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ)

        # ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:
        text += f"ðŸ“… Last Update: {latest_data[0] if len(latest_data)>0 else 'N/A'}\n"
        text += f"ðŸ’° Total Revenue: {latest_data[1] if len(latest_data)>1 else 'N/A'}\n"
        text += f"ðŸ”— Total Clicks: {latest_data[2] if len(latest_data)>2 else 'N/A'}\n"
        text += f"ðŸ›’ Total Sales: {latest_data[3] if len(latest_data)>3 else 'N/A'}\n"
        text += "\n*Data sourced from Google Sheets (statistics table)."
    else:
        text += "No data available. Please ensure the 'statistics' table is populated."

    await callback.message.edit_text(text, reply_markup=get_stats_keyboard())
    await callback.answer("ðŸ“Š Statistics refreshed!", show_alert=False)

async def enter_stats_module(callback: CallbackQuery):
    """ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÑ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ñ€Ð¾Ð´Ð°Ð¶ (called from main_menu.py)."""
    print(f"ðŸ“Š Stats module entered from main menu")

    # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ sheet 'statistics' ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ)
    try:
        stats_data = sheets_api.get_sheet_data("statistics")
        print(f"ðŸ“Š Retrieved {len(stats_data) if stats_data else 0} stats rows")
    except Exception as e:
        print(f"âŒ Error getting stats: {e}")
        stats_data = []

    # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
    text = "**ðŸ“Š Revenue Analytics**\n\n"
    if len(stats_data) > 1:
        headers = stats_data[0]
        latest_data = stats_data[1] # Ð‘ÐµÑ€ÐµÐ¼, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÑ‚Ñ€Ð¾ÐºÑƒ (Ð¾Ð±Ñ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ)

        # ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:
        text += f"ðŸ“… Last Update: {latest_data[0] if len(latest_data)>0 else 'N/A'}\n"
        text += f"ðŸ’° Total Revenue: {latest_data[1] if len(latest_data)>1 else 'N/A'}\n"
        text += f"ðŸ”— Total Clicks: {latest_data[2] if len(latest_data)>2 else 'N/A'}\n"
        text += f"ðŸ›’ Total Sales: {latest_data[3] if len(latest_data)>3 else 'N/A'}\n"
        text += "\n*Data sourced from Google Sheets (statistics table)."
    else:
        text += "No data available. Please ensure the 'statistics' table is populated."

    await callback.message.edit_text(text, reply_markup=get_stats_keyboard())
    await callback.answer()

@router.callback_query(F.data == "stats_upload_csv")
async def request_csv_upload(callback: CallbackQuery, state: FSMContext):
    """Ð—Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ CSV Ñ„Ð°Ð¹Ð»Ð° Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð¼ Ð¿Ñ€Ð¾Ð´Ð°Ð¶."""
    await state.set_state("waiting_for_csv")
    text = "**ðŸ“¤ Upload Amazon Sales Report**\n\n"
    text += "Please upload your Amazon affiliate sales report CSV file.\n"
    text += "The file should contain columns: Categoria, Prodotto, ASIN, Data, QuantitÃ , Prezzo (â‚¬), Tipo di link, Tag, etc.\n\n"
    text += "Supported format: All_orders CSV from Amazon Associates\n\n"
    text += "â¬…ï¸ Use /menu to return to main menu"

    await callback.message.edit_text(text)
    await callback.answer("ðŸ“¤ Ready for CSV upload", show_alert=False)

@router.callback_query(F.data == "stats_view_analytics")
async def show_analytics_menu(callback: CallbackQuery):
    """ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð¼ÐµÐ½ÑŽ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°."""
    text = "**ðŸ“Š Revenue Analytics Dashboard**\n\n"
    text += "Choose your analytics view:\n\n"
    text += "ðŸ“… **Time-based:** Filter by date ranges\n"
    text += "ðŸŽ¯ **Tracking ID:** Filter by specific affiliate tags\n\n"
    text += "Select a period or filter option:"

    await callback.message.edit_text(text, reply_markup=get_analytics_keyboard())
    await callback.answer()

@router.callback_query(F.data.startswith("analytics_period:"))
async def show_period_analytics(callback: CallbackQuery):
    """ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÑƒ Ð·Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´."""
    days = int(callback.data.split(":")[1])

    # Get data from stored CSV or Google Sheets
    analytics_data = await get_analytics_data(days=days)

    text = f"**ðŸ“Š Analytics - Last {days} Days**\n\n"

    if analytics_data:
        text += f"ðŸ’° **Total Revenue:** â‚¬{analytics_data.get('total_revenue', 0):.2f}\n"
        text += f"ðŸ›’ **Total Orders:** {analytics_data.get('total_orders', 0)}\n"
        text += f"ðŸ“¦ **Total Items:** {analytics_data.get('total_items', 0)}\n"
        text += f"ðŸŽ¯ **Active Tracking IDs:** {analytics_data.get('active_tags', 0)}\n\n"

        # Top products
        top_products = analytics_data.get('top_products', [])
        if top_products:
            text += "**ðŸ† Top Products:**\n"
            for i, product in enumerate(top_products[:5], 1):
                text += f"{i}. {product.get('name', 'N/A')} (â‚¬{product.get('revenue', 0):.2f})\n"
    else:
        text += "No data available for this period.\nUpload a CSV report first."

    await callback.message.edit_text(text, reply_markup=get_analytics_keyboard())
    await callback.answer()

@router.callback_query(F.data == "analytics_tracking")
async def request_tracking_id_filter(callback: CallbackQuery, state: FSMContext):
    """Ð—Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Tracking ID Ð´Ð»Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸."""
    await state.set_state("waiting_for_tracking_id")

    # Get available tracking IDs
    available_tags = await get_available_tracking_ids()

    text = "**ðŸŽ¯ Filter by Tracking ID**\n\n"
    if available_tags:
        text += "Available Tracking IDs:\n"
        for tag in available_tags[:10]:  # Show first 10
            text += f"â€¢ {tag}\n"
        text += "\n"
    text += "Enter a Tracking ID to filter analytics:"

    await callback.message.edit_text(text)
    await callback.answer()

@router.callback_query(F.data == "back_to_stats")
async def back_to_stats_menu(callback: CallbackQuery):
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð² Ð³Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸."""
    await enter_stats_module(callback)

@router.message(F.document, F.document.mime_type == "text/csv")
async def handle_csv_upload(message: Message, state: FSMContext):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¹ CSV Ñ„Ð°Ð¹Ð»."""
    try:
        # Check if we're waiting for CSV
        current_state = await state.get_state()
        if current_state != "waiting_for_csv":
            await message.answer("âŒ Not expecting a CSV file right now. Use the statistics menu to upload reports.")
            return

        # Download the file
        file_info = await message.bot.get_file(message.document.file_id)
        file_content = await message.bot.download_file(file_info.file_path)

        # Parse CSV
        csv_data = file_content.read().decode('utf-8')
        df = pd.read_csv(io.StringIO(csv_data), sep=',', quotechar='"')

        # Process the data
        processed_data = await process_amazon_csv(df)

        # Store processed data (you might want to save to database or Google Sheets)
        await store_csv_data(processed_data)

        # Clear state
        await state.clear()

        # Show success message with summary
        summary = processed_data.get('summary', {})
        text = "**âœ… CSV Report Processed Successfully!**\n\n"
        text += f"ðŸ“Š **Report Summary:**\n"
        text += f"â€¢ Orders: {summary.get('total_orders', 0)}\n"
        text += f"â€¢ Revenue: â‚¬{summary.get('total_revenue', 0):.2f}\n"
        text += f"â€¢ Items: {summary.get('total_items', 0)}\n"
        text += f"â€¢ Date Range: {summary.get('date_range', 'N/A')}\n"
        text += f"â€¢ Tracking IDs: {summary.get('tracking_ids', 0)}\n\n"
        text += "Data has been stored and is available in analytics."

        await message.answer(text, reply_markup=get_stats_keyboard())

    except Exception as e:
        await state.clear()
        await message.answer(f"âŒ Error processing CSV file: {str(e)}\n\nPlease ensure it's a valid Amazon All_orders CSV file.")
        print(f"CSV processing error: {e}")

@router.message(F.text & ~F.document)
async def handle_tracking_id_input(message: Message, state: FSMContext):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð²Ð²Ð¾Ð´ Tracking ID Ð´Ð»Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸."""
    current_state = await state.get_state()
    if current_state != "waiting_for_tracking_id":
        return

    tracking_id = message.text.strip()

    # Get analytics for specific tracking ID
    analytics_data = await get_analytics_data(tracking_id=tracking_id)

    await state.clear()

    text = f"**ðŸŽ¯ Analytics for Tracking ID: {tracking_id}**\n\n"

    if analytics_data:
        text += f"ðŸ’° **Revenue:** â‚¬{analytics_data.get('total_revenue', 0):.2f}\n"
        text += f"ðŸ›’ **Orders:** {analytics_data.get('total_orders', 0)}\n"
        text += f"ðŸ“¦ **Items:** {analytics_data.get('total_items', 0)}\n"
        text += f"ðŸ“… **Date Range:** {analytics_data.get('date_range', 'N/A')}\n\n"

        # Show top products for this tracking ID
        top_products = analytics_data.get('top_products', [])
        if top_products:
            text += "**ðŸ† Top Products:**\n"
            for i, product in enumerate(top_products[:5], 1):
                text += f"{i}. {product.get('name', 'N/A')} (â‚¬{product.get('revenue', 0):.2f})\n"
    else:
        text += f"No data found for Tracking ID '{tracking_id}'."

    await message.answer(text, reply_markup=get_analytics_keyboard())

# Helper functions for data processing

async def process_amazon_csv(df: pd.DataFrame) -> Dict[str, Any]:
    """Process Amazon All_orders CSV data."""
    try:
        # Expected columns from the CSV
        expected_cols = ['Categoria', 'Prodotto', 'ASIN', 'Data', 'QuantitÃ ', 'Prezzo (â‚¬)', 'Tipo di link', 'Tag']

        # Check if required columns exist
        missing_cols = [col for col in expected_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")

        # Convert Data column to datetime
        df['Data'] = pd.to_datetime(df['Data'], errors='coerce')

        # Clean and convert price column
        df['Prezzo (â‚¬)'] = pd.to_numeric(df['Prezzo (â‚¬)'].astype(str).str.replace('â‚¬', '').str.replace(',', '.'), errors='coerce')

        # Clean quantity column
        df['QuantitÃ '] = pd.to_numeric(df['QuantitÃ '], errors='coerce')

        # Calculate summary statistics
        total_orders = len(df)
        total_revenue = df['Prezzo (â‚¬)'].sum()
        total_items = df['QuantitÃ '].sum()
        date_range = f"{df['Data'].min().strftime('%Y-%m-%d')} to {df['Data'].max().strftime('%Y-%m-%d')}"
        tracking_ids = df['Tag'].nunique()

        # Top products by revenue
        product_revenue = df.groupby('Prodotto')['Prezzo (â‚¬)'].sum().reset_index()
        top_products = product_revenue.nlargest(10, 'Prezzo (â‚¬)').to_dict('records')

        # Convert to serializable format
        top_products_serialized = [
            {'name': prod['Prodotto'], 'revenue': float(prod['Prezzo (â‚¬)'])}
            for prod in top_products
        ]

        return {
            'summary': {
                'total_orders': int(total_orders),
                'total_revenue': float(total_revenue),
                'total_items': int(total_items),
                'date_range': date_range,
                'tracking_ids': int(tracking_ids)
            },
            'top_products': top_products_serialized,
            'raw_data': df.to_dict('records')
        }

    except Exception as e:
        raise ValueError(f"Error processing CSV: {str(e)}")

async def store_csv_data(data: Dict[str, Any]):
    """Store processed CSV data (placeholder - implement based on your storage needs)."""
    # This could save to database, Google Sheets, or file system
    # For now, we'll just print that data was processed
    print(f"ðŸ“Š Stored CSV data: {data['summary']}")
    # TODO: Implement actual storage logic

async def get_analytics_data(days: int = None, tracking_id: str = None) -> Dict[str, Any]:
    """Get analytics data from stored CSV data."""
    # This is a placeholder - in real implementation, you'd query stored data
    # For now, return mock data
    return {
        'total_revenue': 1250.50,
        'total_orders': 45,
        'total_items': 67,
        'active_tags': 3,
        'date_range': f"Last {days} days" if days else "All time",
        'top_products': [
            {'name': 'Premium Product A', 'revenue': 450.00},
            {'name': 'Best Seller B', 'revenue': 320.50},
            {'name': 'Top Item C', 'revenue': 280.00}
        ]
    }

async def get_available_tracking_ids() -> List[str]:
    """Get list of available tracking IDs from stored data."""
    # This is a placeholder - in real implementation, you'd query stored data
    return ['tag1', 'tag2', 'tag3', 'ivestmente-21', 'lanotizia09-21']
